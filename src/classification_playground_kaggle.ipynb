{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T20:11:03.561017Z","iopub.execute_input":"2021-12-22T20:11:03.561658Z","iopub.status.idle":"2021-12-22T20:11:03.566338Z","shell.execute_reply.started":"2021-12-22T20:11:03.561622Z","shell.execute_reply":"2021-12-22T20:11:03.565678Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working/../input/labeled')","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:35:49.781725Z","iopub.execute_input":"2021-12-22T18:35:49.781999Z","iopub.status.idle":"2021-12-22T18:35:49.791211Z","shell.execute_reply.started":"2021-12-22T18:35:49.781970Z","shell.execute_reply":"2021-12-22T18:35:49.790475Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"PROJECT_ROOT = '/kaggle/working/'\n\nDATASET_PATH = os.path.join(PROJECT_ROOT, '../input/labeled')\nCHECKPOINTS_PATH = os.path.join(PROJECT_ROOT, 'checkpoints')\nPLOTS_PATH = os.path.join(CHECKPOINTS_PATH, 'plots')\nos.makedirs(PLOTS_PATH, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:36:07.124859Z","iopub.execute_input":"2021-12-22T18:36:07.125438Z","iopub.status.idle":"2021-12-22T18:36:07.130265Z","shell.execute_reply.started":"2021-12-22T18:36:07.125401Z","shell.execute_reply":"2021-12-22T18:36:07.129243Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class UnNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n\n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n          tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n          Tensor: Normalized image.\n        \"\"\"\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n          # The normalize code -> t.sub_(m).div_(s)\n        return tensor\n\nMEANS = [0.485, 0.456, 0.406]\nSTDS = [0.229, 0.224, 0.225]\nunorm = UnNormalize(MEANS, STDS)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:36:08.885681Z","iopub.execute_input":"2021-12-22T18:36:08.886390Z","iopub.status.idle":"2021-12-22T18:36:08.892054Z","shell.execute_reply.started":"2021-12-22T18:36:08.886354Z","shell.execute_reply":"2021-12-22T18:36:08.891189Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class MetricTracker:\n    def __init__(self):\n        self.batches_cnt = 0\n        self.total_loss = 0\n        self.avg_loss = 0\n        \n        self.confusion_cnt = {'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0}\n        self.confusion_arrays = {'tp': [], 'tn': [], 'fp': [], 'fn': []}\n        \n        \n    def update(self, loss, preds, labels):\n        self.batches_cnt += 1\n        \n        self.total_loss += float(loss)\n        self.avg_loss = self.total_loss / self.batches_cnt\n\n        preds_sigmoid = torch.sigmoid(preds)\n        preds_binary = preds_sigmoid > 0.5\n\n        for i in range(len(labels)):        \n            curr_key = ''\n            if preds_binary[i] == 0 and labels[i] == 0:\n                curr_key = 'tn'\n            elif preds_binary[i] == 1 and labels[i] == 1:\n                curr_key = 'tp'\n            elif preds_binary[i] == 0 and labels[i] == 1:\n                curr_key = 'fn'\n            else:\n                curr_key = 'fp'\n                \n            self.confusion_cnt[curr_key] += 1\n            self.confusion_arrays[curr_key].append(float(preds_sigmoid[i]))\n        \n        \n    def get_accuracy(self):\n        confusion_cnt_sum = np.sum([cnt for _, cnt in self.confusion_cnt.items()])\n        accuracy = self.confusion_cnt['tp'] + self.confusion_cnt['tn']\n        accuracy /= confusion_cnt_sum\n        \n        return 100 * accuracy\n    \n    def get_precision(self):\n        precision = self.confusion_cnt['tp'] / \\\n            (self.confusion_cnt['tp'] + self.confusion_cnt['fp'])\n        \n        return precision\n    \n    def get_recall(self):\n        recall = self.confusion_cnt['tp'] / \\\n            (self.confusion_cnt['tp'] + self.confusion_cnt['fn'])\n        \n        return recall","metadata":{"execution":{"iopub.status.busy":"2021-12-22T21:19:50.775869Z","iopub.execute_input":"2021-12-22T21:19:50.776341Z","iopub.status.idle":"2021-12-22T21:19:50.789513Z","shell.execute_reply.started":"2021-12-22T21:19:50.776300Z","shell.execute_reply":"2021-12-22T21:19:50.788506Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"def get_balanced_indices(dataset):\n\n    positive_indices = [i for i in range(len(dataset.samples)) if dataset.samples[i][1] == 1]\n    negative_indices = [i for i in range(len(dataset.samples)) if dataset.samples[i][1] == 0]\n    negative_indices_balanced = np.random.choice(\n        negative_indices, len(positive_indices), replace=False\n        )\n    \n    return np.hstack([\n        np.array(positive_indices), np.array(negative_indices_balanced)\n        ])\n\n\n\ndef load_dataset_ECOL_labeled(\n    root_dir, \n    img_size, \n    batch_size, \n    num_workers=0, \n    shuffle=True,\n    balance=True,\n    transform=None,\n    dataset_size=None,\n    test_size=0.2\n    ):\n\n    MEANS = [0.485, 0.456, 0.406]\n    STDS = [0.229, 0.224, 0.225]\n\n    if transform is None:\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Resize(img_size),\n            # transforms.Grayscale(num_output_channels=3),\n            transforms.Normalize(mean=MEANS, std=STDS),\n            ])\n\n    dataset = ImageFolder(root_dir, transform=transform) \n    \n    if dataset_size is None:\n        dataset_size = len(dataset)\n        \n    if balance:\n        dataset_indices = get_balanced_indices(dataset)\n        \n        if len(dataset_indices) < dataset_size:\n            dataset_size = len(dataset_indices)\n    else:\n        dataset_indices = list(range(len(dataset)))\n    \n    \n    if shuffle:\n        dataset_indices = np.random.choice(\n            dataset_indices, dataset_size, replace=False\n            )\n    else:\n        dataset_indices = dataset_indices[ : dataset_size]\n    \n    val_split_index = int(np.floor(test_size * dataset_size))\n\n    train_indices, val_indices = \\\n        dataset_indices[val_split_index:], dataset_indices[:val_split_index]\n\n    train_sampler = SubsetRandomSampler(train_indices)\n    val_sampler = SubsetRandomSampler(val_indices)\n\n    train_loader = DataLoader(\n        dataset=dataset, shuffle=False, batch_size=batch_size, sampler=train_sampler\n        )\n    val_loader = DataLoader(\n        dataset=dataset, shuffle=False, batch_size=batch_size, sampler=val_sampler\n        )\n\n\n    return train_loader, val_loader","metadata":{"execution":{"iopub.status.busy":"2021-12-22T21:18:04.006807Z","iopub.execute_input":"2021-12-22T21:18:04.007517Z","iopub.status.idle":"2021-12-22T21:18:04.025090Z","shell.execute_reply.started":"2021-12-22T21:18:04.007478Z","shell.execute_reply":"2021-12-22T21:18:04.023443Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"def show_batch_as_grid(input_batch, save_path=None):\n    \n    grid_img = torchvision.utils.make_grid(\n        unorm(input_batch).cpu()\n        )\n\n    plt.figure(figsize=(6 * input_batch.shape[0], 10))\n    plt.imshow(grid_img.permute(1, 2, 0))\n    if save_path is not None:\n        plt.savefig(save_path)\n    plt.close()\n\n    \ndef visualize_false_negatives(inputs, labels, preds, save_path=None):\n    preds_binary = preds > 0.5\n    is_false_negative = ((preds_binary == 0) * (labels == 1)).to(torch.bool).squeeze()\n    \n    if is_false_negative.sum() == 0:\n        return \n\n    false_negatives = inputs[is_false_negative] \n    \n    show_batch_as_grid(false_negatives, save_path)\n\n\ndef visualize_true_positives(inputs, labels, preds, save_path=None):\n    preds_binary = preds > 0.5\n    is_true_positive = ((preds_binary == 1) * (labels == 1)).to(torch.bool).squeeze()\n\n    if is_true_positive.sum() == 0:\n        return\n\n    true_positives = inputs[is_true_positive]\n\n    show_batch_as_grid(true_positives, save_path)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T18:36:14.532700Z","iopub.execute_input":"2021-12-22T18:36:14.533255Z","iopub.status.idle":"2021-12-22T18:36:14.544560Z","shell.execute_reply.started":"2021-12-22T18:36:14.533205Z","shell.execute_reply":"2021-12-22T18:36:14.543789Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nLEARNING_RATE = 0.0005\nMAX_ITERS = 1000\n\nLOADER_PARAMS = {\n    'root_dir': DATASET_PATH, 'img_size': (256, 256), 'batch_size': 32, \n    'dataset_size': None, 'test_size': 0.2, 'balance': True\n    }\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(DEVICE)\n\n# Define the loss function\ncriterion = nn.BCEWithLogitsLoss()\n\n# Loading the Data Loader\ntrain_loader, val_loader = load_dataset_ECOL_labeled(**LOADER_PARAMS)\n\n# Load the pretrained model\nmodel = models.vgg16(pretrained=True)\n\n# Replace the classification layer with the new one\n# Will output the prediction for only 1 class\nmodel.classifier[6] = nn.Linear(4096, 1)\n\n# Move model to GPU\nmodel = model.to(DEVICE)\n\n# Define the optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-22T21:18:21.465873Z","iopub.execute_input":"2021-12-22T21:18:21.466330Z","iopub.status.idle":"2021-12-22T21:18:29.711864Z","shell.execute_reply.started":"2021-12-22T21:18:21.466294Z","shell.execute_reply":"2021-12-22T21:18:29.711137Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"code","source":"def check_balancing(dataloader):\n    positives_cnt = 0\n    for ind in dataloader.sampler.indices:\n        positives_cnt += dataloader.dataset.samples[ind][1]\n\n    print(positives_cnt / len(dataloader.sampler.indices))\n    \n    \ncheck_balancing(train_loader)\ncheck_balancing(val_loader)","metadata":{"execution":{"iopub.status.busy":"2021-12-22T21:19:28.514719Z","iopub.execute_input":"2021-12-22T21:19:28.515393Z","iopub.status.idle":"2021-12-22T21:19:28.522370Z","shell.execute_reply.started":"2021-12-22T21:19:28.515358Z","shell.execute_reply":"2021-12-22T21:19:28.521730Z"},"trusted":true},"execution_count":157,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, epoch_idx=0):\n    \n    # Put the model in training mode\n    model.train()\n    \n    # Initialize the metrics\n    metric_tracker = MetricTracker()\n    if 'sampler' in dir(dataloader):\n        total_batch_num = len(dataloader.sampler.indices) // dataloader.batch_size\n    else:\n        total_batch_num = len(dataloader.dataset) // dataloader.batch_size\n    \n    for i, data in enumerate(dataloader):\n        inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n        labels = labels.unsqueeze(dim=1).to(torch.float32) \n        \n        # Reset the optimizer gradient\n        optimizer.zero_grad()\n        \n        # Forward pass\n        preds = model(inputs)\n            \n        loss = criterion(preds, labels)\n        \n        # Backwards pass and parameter update\n        loss.backward()\n        optimizer.step()\n        \n        # Update the metrics\n        metric_tracker.update(float(loss), preds, labels)\n        \n        if i % 10 == 0:\n            print(f'Train epoch {epoch_idx}, Batch {i}/{total_batch_num}: {float(loss)}')\n    \n    print(f'\\n=== TRAIN - Epoch {epoch_idx} ===')\n    print(f'Avg loss = {metric_tracker.avg_loss}')\n    print(f'Accuracy = {metric_tracker.get_accuracy()}')\n    print(f'Precision = {metric_tracker.get_precision()}')\n    print(f'Recall = {metric_tracker.get_recall()}')\n    print()\n    \n    return metric_tracker\n\n\ndef evaluate(model, dataloader):\n    \n    # Put the model in eval mode\n    model.eval()\n    \n    # Initialize the metrics\n    metric_tracker = MetricTracker()\n    if 'sampler' in dir(dataloader):\n        total_batch_num = len(dataloader.sampler.indices) // dataloader.batch_size\n    else:\n        total_batch_num = len(dataloader.dataset) // dataloader.batch_size\n    \n    for i, data in enumerate(dataloader):\n        inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n        labels = labels.unsqueeze(dim=1).to(torch.float32) \n        \n        # Forward pass\n        preds = model(inputs)\n            \n        loss = criterion(preds, labels)\n        \n        # Update the metrics\n        metric_tracker.update(float(loss), preds, labels)\n        \n        if i % 10 == 0:\n            print(f'Validation - Batch {i}/{total_batch_num}: {float(loss)}')\n    \n    print(f'\\n=== VALIDATION ===')\n    print(f'Avg loss = {metric_tracker.avg_loss}')\n    print(f'Accuracy = {metric_tracker.get_accuracy()}')\n    print(f'Precision = {metric_tracker.get_precision()}')\n    print(f'Recall = {metric_tracker.get_recall()}')\n    print()\n    \n    return metric_tracker\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T20:52:16.190974Z","iopub.execute_input":"2021-12-22T20:52:16.191291Z","iopub.status.idle":"2021-12-22T20:52:16.205171Z","shell.execute_reply.started":"2021-12-22T20:52:16.191258Z","shell.execute_reply":"2021-12-22T20:52:16.203268Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"metrics_per_epoch = {}\n\nfor epoch in range(10):\n    metrics_per_epoch[epoch] = {}\n    \n    train_metrics = train_epoch(model, train_loader, optimizer, epoch)\n    metrics_per_epoch[epoch]['train'] = train_metrics\n    \n    val_metrics = evaluate(model, val_loader)\n    metrics_per_epoch[epoch]['val'] = train_metrics\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-22T21:20:42.275457Z","iopub.execute_input":"2021-12-22T21:20:42.275711Z","iopub.status.idle":"2021-12-22T21:20:46.389580Z","shell.execute_reply.started":"2021-12-22T21:20:42.275683Z","shell.execute_reply":"2021-12-22T21:20:46.388523Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"losses = []\naccuracies = []\n\ntotal_batch_num = len(dataloader.dataset) // dataloader.batch_size\n# Training loop\nfor epoch in range(30):\n    model.train()\n    os.makedirs(os.path.join(PLOTS_PATH, f'epoch_{epoch}'), exist_ok=True)\n\n    if i % 30 == 0:\n        save_path = os.path.join(PLOTS_PATH, f'epoch_{epoch}', f'false_negative_batch_{i}.png')\n        visualize_false_negatives(inputs, labels, preds_sigmoid, save_path)\n\n        save_path = os.path.join(PLOTS_PATH, f'epoch_{epoch}', f'true_positive_batch_{i}.png')\n        visualize_true_positives(inputs, labels, preds_sigmoid, save_path)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:03:06.504613Z","iopub.execute_input":"2021-12-21T17:03:06.504916Z","iopub.status.idle":"2021-12-21T17:13:30.476442Z","shell.execute_reply.started":"2021-12-21T17:03:06.504883Z","shell.execute_reply":"2021-12-21T17:13:30.475257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(TPp)\nplt.xlim([0, 1])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:01:57.132322Z","iopub.status.idle":"2021-12-21T17:01:57.132953Z","shell.execute_reply.started":"2021-12-21T17:01:57.132723Z","shell.execute_reply":"2021-12-21T17:01:57.132746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(TNp)\nplt.xlim([0, 1])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:01:57.134134Z","iopub.status.idle":"2021-12-21T17:01:57.134778Z","shell.execute_reply.started":"2021-12-21T17:01:57.134535Z","shell.execute_reply":"2021-12-21T17:01:57.134559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(FPp)\nplt.xlim([0, 1])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:01:57.135965Z","iopub.status.idle":"2021-12-21T17:01:57.136595Z","shell.execute_reply.started":"2021-12-21T17:01:57.136336Z","shell.execute_reply":"2021-12-21T17:01:57.136359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(FNp)\nplt.xlim([0, 1])","metadata":{"execution":{"iopub.status.busy":"2021-12-21T17:01:57.137767Z","iopub.status.idle":"2021-12-21T17:01:57.138376Z","shell.execute_reply.started":"2021-12-21T17:01:57.138147Z","shell.execute_reply":"2021-12-21T17:01:57.138171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}